import requests
from bs4 import BeautifulSoup
import os
import re
import time

# -----------------------------------------------------------
# [í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì„¤ì •] â˜…ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”â˜…
# í…ŒìŠ¤íŠ¸í•˜ê³  ì‹¶ì€ ê²Œì‹œíŒì˜ Noneì„ 'ê¸°ì¤€ ë²ˆí˜¸(ìˆ«ì)'ë¡œ ë°”ê¾¸ì„¸ìš”.
# ì˜ˆ: "general": 1336480
# í…ŒìŠ¤íŠ¸ê°€ ëë‚˜ë©´ ë‹¤ì‹œ ëª¨ë‘ Noneìœ¼ë¡œ ëŒë ¤ë†“ìœ¼ì„¸ìš” (ìë™ ëª¨ë“œ).
# -----------------------------------------------------------
TEST_IDS = {
    "general": None,      # ğŸ“¢ ì „ì²´ê³µì§€ (doc_no ê¸°ì¤€)
    "academic": None,     # ğŸ“ í•™ì‚¬ê³µì§€ (bltn_no ê¸°ì¤€)
    "electronic": None    # âš¡ ì „ìê³µí•™ë¶€ (no ê¸°ì¤€)
}

# -----------------------------------------------------------
# [ê²Œì‹œíŒ ì„¤ì •]
# -----------------------------------------------------------
BOARDS = [
    {
        "id_key": "general", # TEST_IDSì˜ í‚¤ì™€ ì¼ì¹˜
        "name": "ğŸ“¢ ì „ì²´ê³µì§€",
        "url": "https://www.knu.ac.kr/wbbs/wbbs/bbs/btin/list.action?bbs_cde=1&menu_idx=67",
        "view_base": "https://www.knu.ac.kr/wbbs/wbbs/bbs/btin/viewBtin.action?btin.bbs_cde=1&btin.appl_no=000000&menu_idx=67&btin.doc_no=",
        "file": "latest_id_general.txt",
        "type": "knu_general",
        "env_key": "WEBHOOK_GENERAL"
    },
    {
        "id_key": "academic",
        "name": "ğŸ“ í•™ì‚¬ê³µì§€",
        "url": "https://www.knu.ac.kr/wbbs/wbbs/bbs/btin/stdList.action?menu_idx=42",
        "view_base": "https://www.knu.ac.kr/wbbs/wbbs/bbs/btin/stdViewBtin.action?menu_idx=42",
        "file": "latest_id_academic.txt",
        "type": "knu_academic",
        "env_key": "WEBHOOK_ACADEMIC"
    },
    {
        "id_key": "electronic",
        "name": "âš¡ ì „ìê³µí•™ë¶€",
        "url": "https://see.knu.ac.kr/content/board/notice.html",
        "view_base": "https://see.knu.ac.kr/content/board/notice.html?f=view&no=",
        "file": "latest_id_electronic.txt",
        "type": "see_knu",
        "env_key": "WEBHOOK_ELECTRONIC"
    }
]

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# -----------------------------------------------------------
# [í—¤ë”] ë³´ì•ˆ ìš°íšŒìš©
# -----------------------------------------------------------
COMMON_HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Connection': 'keep-alive',
    'Upgrade-Insecure-Requests': '1'
}

# -----------------------------------------------------------
# [ê¸°ëŠ¥ 1] ë³¸ë¬¸ í¬ë¡¤ë§
# -----------------------------------------------------------
def get_post_content(url):
    try:
        requests.packages.urllib3.disable_warnings()
        headers = COMMON_HEADERS.copy()
        
        # ì „ìê³µí•™ë¶€ëŠ” Refererê°€ ìê¸° ìì‹ ì´ì–´ì•¼ ì˜ ë¨
        if "see.knu.ac.kr" in url:
            headers['Referer'] = "https://see.knu.ac.kr/"
        else:
            headers['Referer'] = "https://www.knu.ac.kr/"
        
        response = requests.get(url, headers=headers, verify=False)
        response.encoding = 'UTF-8'
        soup = BeautifulSoup(response.text, 'html.parser')

        # ë³¸ë¬¸ ì°¾ê¸° í›„ë³´êµ° (ê²½ë¶ëŒ€ ë³¸ê´€ + ì „ìê³µí•™ë¶€ ìŠ¤íƒ€ì¼)
        # .board-view : ì „ìê³µí•™ë¶€ ìŠ¤íƒ€ì¼
        # .board_cont : ê²½ë¶ëŒ€ ë³¸ê´€ ìŠ¤íƒ€ì¼
        candidates = ['.board_cont', '.board-view', '.view_con', '.content', '.tbl_view', '.board_view_con']
        
        content_div = None
        for selector in candidates:
            content_div = soup.select_one(selector)
            if content_div: break
        
        if content_div:
            return content_div.get_text(separator="\n", strip=True)
        return "ë³¸ë¬¸ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    except Exception as e:
        print(f"   ë³¸ë¬¸ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return "ë³¸ë¬¸ ë¡œë”© ì‹¤íŒ¨"

# -----------------------------------------------------------
# [ê¸°ëŠ¥ 2] ë””ìŠ¤ì½”ë“œ ì „ì†¡
# -----------------------------------------------------------
def send_discord_message(webhook_url, board_name, title, link, doc_id, original_content):
    # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° (500ì ì œí•œ)
    clean = original_content[:500] + ("..." if len(original_content) > 500 else "")
    
    # ë‚´ìš©ì´ ë„ˆë¬´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
    if not clean.strip():
        clean = "(ë³¸ë¬¸ ë‚´ìš©ì´ ì—†ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•œ ê²Œì‹œê¸€ì…ë‹ˆë‹¤)"

    description = f"**[ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°]**\n{clean}"
    footer_text = f"{board_name} â€¢ ID: {doc_id}"

    data = {
        "content": f"ğŸ”” **{board_name} ì—…ë°ì´íŠ¸**",
        "embeds": [{
            "title": title,
            "description": description,
            "url": link,
            "color": 3447003, # Blue
            "footer": {"text": footer_text}
        }]
    }
    
    try:
        requests.post(webhook_url, json=data)
        print(f"ğŸš€ [ì „ì†¡ ì„±ê³µ] {title}")
    except Exception as e:
        print(f"âŒ [ì „ì†¡ ì‹¤íŒ¨] {e}")

# -----------------------------------------------------------
# [ë©”ì¸] ë¡œì§
# -----------------------------------------------------------
def main():
    requests.packages.urllib3.disable_warnings()
    print("--- [í†µí•© ê³µì§€ í¬ë¡¤ëŸ¬ ì‹œì‘] ---")
    
    for board in BOARDS:
        print(f"\nğŸ” ê²€ì‚¬ ì¤‘: {board['name']}")
        
        # 1. í…ŒìŠ¤íŠ¸ ID í™•ì¸
        test_id = TEST_IDS.get(board['id_key'])
        
        if test_id is not None:
            last_id = int(test_id)
            print(f"   âš ï¸ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] ê°•ì œ ê¸°ì¤€ ID: {last_id}")
        else:
            # íŒŒì¼ì—ì„œ ì½ê¸°
            file_path = os.path.join(BASE_DIR, board['file'])
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    last_id = int(content) if content else 0
            except FileNotFoundError:
                last_id = 0
            print(f"   ğŸ“‚ ì €ì¥ëœ ID (íŒŒì¼): {last_id}")

        # 2. ì›¹í›… URL í™•ì¸
        webhook_url = os.environ.get(board['env_key'])
        if not webhook_url:
            print(f"   ğŸš¨ ê²½ê³ : ì›¹í›…({board['env_key']}) ì—†ìŒ. ê±´ë„ˆëœ€.")
            continue

        # 3. ëª©ë¡ ì ‘ì†
        try:
            headers = COMMON_HEADERS.copy()
            headers['Referer'] = board['url']
            response = requests.get(board['url'], headers=headers, verify=False)
            response.encoding = 'UTF-8'
            soup = BeautifulSoup(response.text, 'html.parser')
        except Exception as e:
            print(f"   ğŸš¨ ì ‘ì† ì‹¤íŒ¨: {e}")
            continue

        rows = soup.select("tbody > tr")
        if not rows: rows = soup.select("tr")

        new_posts = []

        for row in rows:
            cols = row.select("td")
            if len(cols) < 2: continue
            
            # ì œëª© ì°¾ê¸° (a íƒœê·¸)
            title_tag = cols[1].find("a") 
            if not title_tag: 
                # ì „ìê³µí•™ë¶€ ë“± êµ¬ì¡°ê°€ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ row ì „ì²´ ê²€ìƒ‰
                title_tag = row.find("a")
            
            if not title_tag: continue

            title = title_tag.text.strip()
            href = title_tag.get('href', '')

            # 4. ID ì¶”ì¶œ ë° ë§í¬ ìƒì„±
            doc_id = 0
            real_link = ""
            
            try:
                # A. ì „ìê³µí•™ë¶€ (no=...)
                if board['type'] == 'see_knu':
                    match = re.search(r"no=(\d+)", href)
                    if match:
                        doc_id = int(match.group(1))
                        real_link = board['view_base'] + str(doc_id)

                # B. í•™ì‚¬ê³µì§€ (bltn_no, inpt_nbr)
                elif board['type'] == 'knu_academic':
                    numbers = re.findall(r"(\d+)", href)
                    if numbers:
                        doc_id = int(numbers[0])
                        # ë§í¬ ì¡°ë¦½ (inpt_nbrì´ ìˆìœ¼ë©´ ê°™ì´ ë„£ìŒ)
                        if len(numbers) >= 2:
                             real_link = f"{board['view_base']}&btin.bltn_no={numbers[0]}&btin.inpt_nbr={numbers[1]}"
                        else:
                             real_link = f"{board['view_base']}&btin.bltn_no={numbers[0]}"

                # C. ì „ì²´ê³µì§€ (doc_no)
                else: 
                    match = re.search(r"(\d+)", href)
                    if match:
                        doc_id = int(match.group(1))
                        real_link = board['view_base'] + str(doc_id)

            except Exception:
                continue

            # 5. ìƒˆ ê¸€ íŒë‹¨
            if doc_id > 0 and doc_id > last_id:
                print(f"   âœ… ìƒˆ ê¸€ ë°œê²¬: {doc_id} - {title}")
                new_posts.append({'id': doc_id, 'title': title, 'link': real_link})

        # 6. ì „ì†¡ ë° ì €ì¥
        if new_posts:
            # ê³¼ê±°ìˆœ ì •ë ¬
            new_posts.sort(key=lambda x: x['id'])
            
            for post in new_posts:
                # ë³¸ë¬¸ ê¸ì–´ì˜¤ê¸°
                content = get_post_content(post['link'])
                # ë””ìŠ¤ì½”ë“œ ì „ì†¡
                send_discord_message(webhook_url, board['name'], post['title'], post['link'], post['id'], content)
                time.sleep(1)

            # â˜… ì¤‘ìš”: í…ŒìŠ¤íŠ¸ ëª¨ë“œê°€ ì•„ë‹ ë•Œë§Œ íŒŒì¼ ì—…ë°ì´íŠ¸
            if test_id is None:
                max_id = max(p['id'] for p in new_posts)
                file_path = os.path.join(BASE_DIR, board['file'])
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(str(max_id))
                print(f"   ğŸ’¾ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {max_id}")
            else:
                print("   âš ï¸ [í…ŒìŠ¤íŠ¸ ëª¨ë“œ] íŒŒì¼ ì €ì¥ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        else:
            print("   ğŸ’¤ ìƒˆ ê¸€ ì—†ìŒ")

if __name__ == "__main__":
    main()
